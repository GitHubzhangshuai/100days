
# Multiple Linear Regression(多元线性回归)

## Step 1: Data Preprocessing(数据预处理)

### Importing the libraries(导入库)


```python
import pandas as pd
import numpy as np
```

### Importing the dataset(导入数据集)


```python
dataset = pd.read_csv('50_Startups.csv')
dataset
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>R&amp;D Spend</th>
      <th>Administration</th>
      <th>Marketing Spend</th>
      <th>State</th>
      <th>Profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>165349.20</td>
      <td>136897.80</td>
      <td>471784.10</td>
      <td>New York</td>
      <td>192261.83</td>
    </tr>
    <tr>
      <th>1</th>
      <td>162597.70</td>
      <td>151377.59</td>
      <td>443898.53</td>
      <td>California</td>
      <td>191792.06</td>
    </tr>
    <tr>
      <th>2</th>
      <td>153441.51</td>
      <td>101145.55</td>
      <td>407934.54</td>
      <td>Florida</td>
      <td>191050.39</td>
    </tr>
    <tr>
      <th>3</th>
      <td>144372.41</td>
      <td>118671.85</td>
      <td>383199.62</td>
      <td>New York</td>
      <td>182901.99</td>
    </tr>
    <tr>
      <th>4</th>
      <td>142107.34</td>
      <td>91391.77</td>
      <td>366168.42</td>
      <td>Florida</td>
      <td>166187.94</td>
    </tr>
    <tr>
      <th>5</th>
      <td>131876.90</td>
      <td>99814.71</td>
      <td>362861.36</td>
      <td>New York</td>
      <td>156991.12</td>
    </tr>
    <tr>
      <th>6</th>
      <td>134615.46</td>
      <td>147198.87</td>
      <td>127716.82</td>
      <td>California</td>
      <td>156122.51</td>
    </tr>
    <tr>
      <th>7</th>
      <td>130298.13</td>
      <td>145530.06</td>
      <td>323876.68</td>
      <td>Florida</td>
      <td>155752.60</td>
    </tr>
    <tr>
      <th>8</th>
      <td>120542.52</td>
      <td>148718.95</td>
      <td>311613.29</td>
      <td>New York</td>
      <td>152211.77</td>
    </tr>
    <tr>
      <th>9</th>
      <td>123334.88</td>
      <td>108679.17</td>
      <td>304981.62</td>
      <td>California</td>
      <td>149759.96</td>
    </tr>
    <tr>
      <th>10</th>
      <td>101913.08</td>
      <td>110594.11</td>
      <td>229160.95</td>
      <td>Florida</td>
      <td>146121.95</td>
    </tr>
    <tr>
      <th>11</th>
      <td>100671.96</td>
      <td>91790.61</td>
      <td>249744.55</td>
      <td>California</td>
      <td>144259.40</td>
    </tr>
    <tr>
      <th>12</th>
      <td>93863.75</td>
      <td>127320.38</td>
      <td>249839.44</td>
      <td>Florida</td>
      <td>141585.52</td>
    </tr>
    <tr>
      <th>13</th>
      <td>91992.39</td>
      <td>135495.07</td>
      <td>252664.93</td>
      <td>California</td>
      <td>134307.35</td>
    </tr>
    <tr>
      <th>14</th>
      <td>119943.24</td>
      <td>156547.42</td>
      <td>256512.92</td>
      <td>Florida</td>
      <td>132602.65</td>
    </tr>
    <tr>
      <th>15</th>
      <td>114523.61</td>
      <td>122616.84</td>
      <td>261776.23</td>
      <td>New York</td>
      <td>129917.04</td>
    </tr>
    <tr>
      <th>16</th>
      <td>78013.11</td>
      <td>121597.55</td>
      <td>264346.06</td>
      <td>California</td>
      <td>126992.93</td>
    </tr>
    <tr>
      <th>17</th>
      <td>94657.16</td>
      <td>145077.58</td>
      <td>282574.31</td>
      <td>New York</td>
      <td>125370.37</td>
    </tr>
    <tr>
      <th>18</th>
      <td>91749.16</td>
      <td>114175.79</td>
      <td>294919.57</td>
      <td>Florida</td>
      <td>124266.90</td>
    </tr>
    <tr>
      <th>19</th>
      <td>86419.70</td>
      <td>153514.11</td>
      <td>0.00</td>
      <td>New York</td>
      <td>122776.86</td>
    </tr>
    <tr>
      <th>20</th>
      <td>76253.86</td>
      <td>113867.30</td>
      <td>298664.47</td>
      <td>California</td>
      <td>118474.03</td>
    </tr>
    <tr>
      <th>21</th>
      <td>78389.47</td>
      <td>153773.43</td>
      <td>299737.29</td>
      <td>New York</td>
      <td>111313.02</td>
    </tr>
    <tr>
      <th>22</th>
      <td>73994.56</td>
      <td>122782.75</td>
      <td>303319.26</td>
      <td>Florida</td>
      <td>110352.25</td>
    </tr>
    <tr>
      <th>23</th>
      <td>67532.53</td>
      <td>105751.03</td>
      <td>304768.73</td>
      <td>Florida</td>
      <td>108733.99</td>
    </tr>
    <tr>
      <th>24</th>
      <td>77044.01</td>
      <td>99281.34</td>
      <td>140574.81</td>
      <td>New York</td>
      <td>108552.04</td>
    </tr>
    <tr>
      <th>25</th>
      <td>64664.71</td>
      <td>139553.16</td>
      <td>137962.62</td>
      <td>California</td>
      <td>107404.34</td>
    </tr>
    <tr>
      <th>26</th>
      <td>75328.87</td>
      <td>144135.98</td>
      <td>134050.07</td>
      <td>Florida</td>
      <td>105733.54</td>
    </tr>
    <tr>
      <th>27</th>
      <td>72107.60</td>
      <td>127864.55</td>
      <td>353183.81</td>
      <td>New York</td>
      <td>105008.31</td>
    </tr>
    <tr>
      <th>28</th>
      <td>66051.52</td>
      <td>182645.56</td>
      <td>118148.20</td>
      <td>Florida</td>
      <td>103282.38</td>
    </tr>
    <tr>
      <th>29</th>
      <td>65605.48</td>
      <td>153032.06</td>
      <td>107138.38</td>
      <td>New York</td>
      <td>101004.64</td>
    </tr>
    <tr>
      <th>30</th>
      <td>61994.48</td>
      <td>115641.28</td>
      <td>91131.24</td>
      <td>Florida</td>
      <td>99937.59</td>
    </tr>
    <tr>
      <th>31</th>
      <td>61136.38</td>
      <td>152701.92</td>
      <td>88218.23</td>
      <td>New York</td>
      <td>97483.56</td>
    </tr>
    <tr>
      <th>32</th>
      <td>63408.86</td>
      <td>129219.61</td>
      <td>46085.25</td>
      <td>California</td>
      <td>97427.84</td>
    </tr>
    <tr>
      <th>33</th>
      <td>55493.95</td>
      <td>103057.49</td>
      <td>214634.81</td>
      <td>Florida</td>
      <td>96778.92</td>
    </tr>
    <tr>
      <th>34</th>
      <td>46426.07</td>
      <td>157693.92</td>
      <td>210797.67</td>
      <td>California</td>
      <td>96712.80</td>
    </tr>
    <tr>
      <th>35</th>
      <td>46014.02</td>
      <td>85047.44</td>
      <td>205517.64</td>
      <td>New York</td>
      <td>96479.51</td>
    </tr>
    <tr>
      <th>36</th>
      <td>28663.76</td>
      <td>127056.21</td>
      <td>201126.82</td>
      <td>Florida</td>
      <td>90708.19</td>
    </tr>
    <tr>
      <th>37</th>
      <td>44069.95</td>
      <td>51283.14</td>
      <td>197029.42</td>
      <td>California</td>
      <td>89949.14</td>
    </tr>
    <tr>
      <th>38</th>
      <td>20229.59</td>
      <td>65947.93</td>
      <td>185265.10</td>
      <td>New York</td>
      <td>81229.06</td>
    </tr>
    <tr>
      <th>39</th>
      <td>38558.51</td>
      <td>82982.09</td>
      <td>174999.30</td>
      <td>California</td>
      <td>81005.76</td>
    </tr>
    <tr>
      <th>40</th>
      <td>28754.33</td>
      <td>118546.05</td>
      <td>172795.67</td>
      <td>California</td>
      <td>78239.91</td>
    </tr>
    <tr>
      <th>41</th>
      <td>27892.92</td>
      <td>84710.77</td>
      <td>164470.71</td>
      <td>Florida</td>
      <td>77798.83</td>
    </tr>
    <tr>
      <th>42</th>
      <td>23640.93</td>
      <td>96189.63</td>
      <td>148001.11</td>
      <td>California</td>
      <td>71498.49</td>
    </tr>
    <tr>
      <th>43</th>
      <td>15505.73</td>
      <td>127382.30</td>
      <td>35534.17</td>
      <td>New York</td>
      <td>69758.98</td>
    </tr>
    <tr>
      <th>44</th>
      <td>22177.74</td>
      <td>154806.14</td>
      <td>28334.72</td>
      <td>California</td>
      <td>65200.33</td>
    </tr>
    <tr>
      <th>45</th>
      <td>1000.23</td>
      <td>124153.04</td>
      <td>1903.93</td>
      <td>New York</td>
      <td>64926.08</td>
    </tr>
    <tr>
      <th>46</th>
      <td>1315.46</td>
      <td>115816.21</td>
      <td>297114.46</td>
      <td>Florida</td>
      <td>49490.75</td>
    </tr>
    <tr>
      <th>47</th>
      <td>0.00</td>
      <td>135426.92</td>
      <td>0.00</td>
      <td>California</td>
      <td>42559.73</td>
    </tr>
    <tr>
      <th>48</th>
      <td>542.05</td>
      <td>51743.15</td>
      <td>0.00</td>
      <td>New York</td>
      <td>35673.41</td>
    </tr>
    <tr>
      <th>49</th>
      <td>0.00</td>
      <td>116983.80</td>
      <td>45173.06</td>
      <td>California</td>
      <td>14681.40</td>
    </tr>
  </tbody>
</table>
</div>




```python
X = dataset.iloc[:,:-1].values
Y = dataset.iloc[:,4].values
X,Y
```




    (array([[165349.2, 136897.8, 471784.1, 'New York'],
            [162597.7, 151377.59, 443898.53, 'California'],
            [153441.51, 101145.55, 407934.54, 'Florida'],
            [144372.41, 118671.85, 383199.62, 'New York'],
            [142107.34, 91391.77, 366168.42, 'Florida'],
            [131876.9, 99814.71, 362861.36, 'New York'],
            [134615.46, 147198.87, 127716.82, 'California'],
            [130298.13, 145530.06, 323876.68, 'Florida'],
            [120542.52, 148718.95, 311613.29, 'New York'],
            [123334.88, 108679.17, 304981.62, 'California'],
            [101913.08, 110594.11, 229160.95, 'Florida'],
            [100671.96, 91790.61, 249744.55, 'California'],
            [93863.75, 127320.38, 249839.44, 'Florida'],
            [91992.39, 135495.07, 252664.93, 'California'],
            [119943.24, 156547.42, 256512.92, 'Florida'],
            [114523.61, 122616.84, 261776.23, 'New York'],
            [78013.11, 121597.55, 264346.06, 'California'],
            [94657.16, 145077.58, 282574.31, 'New York'],
            [91749.16, 114175.79, 294919.57, 'Florida'],
            [86419.7, 153514.11, 0.0, 'New York'],
            [76253.86, 113867.3, 298664.47, 'California'],
            [78389.47, 153773.43, 299737.29, 'New York'],
            [73994.56, 122782.75, 303319.26, 'Florida'],
            [67532.53, 105751.03, 304768.73, 'Florida'],
            [77044.01, 99281.34, 140574.81, 'New York'],
            [64664.71, 139553.16, 137962.62, 'California'],
            [75328.87, 144135.98, 134050.07, 'Florida'],
            [72107.6, 127864.55, 353183.81, 'New York'],
            [66051.52, 182645.56, 118148.2, 'Florida'],
            [65605.48, 153032.06, 107138.38, 'New York'],
            [61994.48, 115641.28, 91131.24, 'Florida'],
            [61136.38, 152701.92, 88218.23, 'New York'],
            [63408.86, 129219.61, 46085.25, 'California'],
            [55493.95, 103057.49, 214634.81, 'Florida'],
            [46426.07, 157693.92, 210797.67, 'California'],
            [46014.02, 85047.44, 205517.64, 'New York'],
            [28663.76, 127056.21, 201126.82, 'Florida'],
            [44069.95, 51283.14, 197029.42, 'California'],
            [20229.59, 65947.93, 185265.1, 'New York'],
            [38558.51, 82982.09, 174999.3, 'California'],
            [28754.33, 118546.05, 172795.67, 'California'],
            [27892.92, 84710.77, 164470.71, 'Florida'],
            [23640.93, 96189.63, 148001.11, 'California'],
            [15505.73, 127382.3, 35534.17, 'New York'],
            [22177.74, 154806.14, 28334.72, 'California'],
            [1000.23, 124153.04, 1903.93, 'New York'],
            [1315.46, 115816.21, 297114.46, 'Florida'],
            [0.0, 135426.92, 0.0, 'California'],
            [542.05, 51743.15, 0.0, 'New York'],
            [0.0, 116983.8, 45173.06, 'California']], dtype=object),
     array([192261.83, 191792.06, 191050.39, 182901.99, 166187.94, 156991.12,
            156122.51, 155752.6 , 152211.77, 149759.96, 146121.95, 144259.4 ,
            141585.52, 134307.35, 132602.65, 129917.04, 126992.93, 125370.37,
            124266.9 , 122776.86, 118474.03, 111313.02, 110352.25, 108733.99,
            108552.04, 107404.34, 105733.54, 105008.31, 103282.38, 101004.64,
             99937.59,  97483.56,  97427.84,  96778.92,  96712.8 ,  96479.51,
             90708.19,  89949.14,  81229.06,  81005.76,  78239.91,  77798.83,
             71498.49,  69758.98,  65200.33,  64926.08,  49490.75,  42559.73,
             35673.41,  14681.4 ]))



### Encoding Categorical data(将类别数据数字化)


```python
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder = LabelEncoder()
X[:,3]=labelencoder.fit_transform(X[:,3])
onehotencoder=OneHotEncoder(categorical_features=[3])
X=onehotencoder.fit_transform(X).toarray()
X
```

    C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\preprocessing\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.
    If you want the future behaviour and silence this warning, you can specify "categories='auto'".
    In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.
      warnings.warn(msg, FutureWarning)
    C:\Users\张帅\AppData\Roaming\Python\Python36\site-packages\sklearn\preprocessing\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.
      "use the ColumnTransformer instead.", DeprecationWarning)
    




    array([[1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 1.0000000e+00,
            1.3689780e+05, 4.7178410e+05],
           [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
            1.5137759e+05, 4.4389853e+05],
           [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
            1.0114555e+05, 4.0793454e+05],
           ...,
           [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
            1.3542692e+05, 0.0000000e+00],
           [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,
            5.1743150e+04, 0.0000000e+00],
           [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
            1.1698380e+05, 4.5173060e+04]])



### Avoiding Dummy Variable Trap(躲避虚拟变量陷阱)


```python
X = X[:, 1:]
X
```




    array([[1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 1.0000000e+00,
            1.3689780e+05, 4.7178410e+05],
           [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
            1.5137759e+05, 4.4389853e+05],
           [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
            1.0114555e+05, 4.0793454e+05],
           ...,
           [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
            1.3542692e+05, 0.0000000e+00],
           [0.0000000e+00, 1.0000000e+00, 1.0000000e+00, ..., 1.0000000e+00,
            5.1743150e+04, 0.0000000e+00],
           [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
            1.1698380e+05, 4.5173060e+04]])



### Splitting the dataset into the Training set and Test set(拆分数据集为训练集和测试集
)


```python
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)
X_train, X_test, Y_train, Y_test
```




    (array([[1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
             1.0305749e+05, 2.1463481e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 1.0000000e+00,
             8.5047440e+04, 2.0551764e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
             1.4413598e+05, 1.3405007e+05],
            ...,
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 1.0000000e+00,
             1.3689780e+05, 4.7178410e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
             1.3542692e+05, 0.0000000e+00],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,
             1.5480614e+05, 2.8334720e+04]]),
     array([[1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,
             0.0000000e+00, 1.8264556e+05, 1.1814820e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 9.1790610e+04, 2.4974455e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,
             0.0000000e+00, 1.1059411e+05, 2.2916095e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,
             0.0000000e+00, 8.4710770e+04, 1.6447071e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,
             0.0000000e+00, 1.0114555e+05, 4.0793454e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             1.0000000e+00, 1.2786455e+05, 3.5318381e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             1.0000000e+00, 6.5947930e+04, 1.8526510e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             1.0000000e+00, 1.5270192e+05, 8.8218230e+04],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,
             0.0000000e+00, 1.2278275e+05, 3.0331926e+05],
            [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,
             0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,
             0.0000000e+00, 9.1391770e+04, 3.6616842e+05]]),
     array([ 96778.92,  96479.51, 105733.54,  96712.8 , 124266.9 , 155752.6 ,
            132602.65,  64926.08,  35673.41, 101004.64, 129917.04,  99937.59,
             97427.84, 126992.93,  71498.49, 118474.03,  69758.98, 152211.77,
            134307.35, 107404.34, 156991.12, 125370.37,  78239.91,  14681.4 ,
            191792.06, 141585.52,  89949.14, 108552.04, 156122.51, 108733.99,
             90708.19, 111313.02, 122776.86, 149759.96,  81005.76,  49490.75,
            182901.99, 192261.83,  42559.73,  65200.33]),
     array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,
             81229.06,  97483.56, 110352.25, 166187.94]))



## Step 2: Fitting Multiple Linear Regression to the Training set( 在训练集上训练多元线性回归模型)


```python
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train,Y_train)
```




    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
             normalize=False)



## Step 3: Predicting the Test set results(在测试集上预测结果)


```python
y_pred=regressor.predict(X_test)
y_pred
```




    array([199284.29616179,  58975.97231506,  84818.06472524,  34825.52114832,
            83740.4976782 , 136541.34536323,  15834.62401121, 156765.35558325,
           112067.27328005,  63426.14627526])


